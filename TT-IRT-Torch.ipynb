{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import lr_scheduler\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def interp1(grid, x, f, axis=0):  # Linear interpolation\n",
    "    s = torch.ones(f.dim(), dtype=torch.long)\n",
    "    s[axis] = x.numel()\n",
    "    s = torch.Size(s)\n",
    "    ind = torch.searchsorted(grid, x) # indices on the right of x\n",
    "    ind = torch.minimum(torch.maximum(ind, torch.tensor(1)), torch.tensor(grid.numel()-1))\n",
    "    gr = grid[ind].view(s)\n",
    "    gl = grid[ind-1].view(s)\n",
    "    fr = torch.index_select(f,axis,ind)\n",
    "    fl = torch.index_select(f,axis,ind-1)\n",
    "    xt = x.view(s)\n",
    "    return (fr * (xt - gl) + fl * (gr - xt)) / (gr - gl)\n",
    "\n",
    "def linearMass(grid):   # Mass matrix of piecewise linear functions\n",
    "    h = grid[1:] - grid[:-1]\n",
    "    h = torch.cat([h[0].reshape(1), h, h[-1].reshape(1)])\n",
    "    M = torch.diag(h[1:-1]/6, -1) + torch.diag(h[1:-1]/6, 1) + torch.diag((h[:-1]+h[1:])/3)\n",
    "    M[0,0] = h[1]/3 \n",
    "    M[-1,-1] = h[-1]/3\n",
    "    return M\n",
    "\n",
    "def linearLap(grid):    # Laplacian matrix of piecewise linear functions\n",
    "    h = grid[1:] - grid[:-1]\n",
    "    h = torch.cat([h[0].reshape(1), h, h[-1].reshape(1)])\n",
    "    M = torch.diag(-1/h[1:-1], -1) + torch.diag(-1/h[1:-1], 1) + torch.diag(1/h[:-1]+1/h[1:])\n",
    "    M[0,0] = 1/h[1]\n",
    "    M[-1,-1] = 1/h[-1]\n",
    "    return M\n",
    "\n",
    "class TT(nn.Module): # Discrete TT(i) = <U, e_i> for general purpose with MSE loss\n",
    "    def __init__(self, n=[1], r=[1,1]):\n",
    "        super().__init__()\n",
    "        self.U = nn.ParameterList([nn.Parameter(torch.rand(r[i], n[i], r[i + 1])*1e-3) for i in range(len(n))])\n",
    "\n",
    "    def loss(self, X, Y):\n",
    "        return torch.mean((self.forward(X) - Y)**2)        \n",
    "\n",
    "class TTLin(TT): # Linear TT(x) = <U, \\phi(x)> for general purpose with MSE loss\n",
    "    def __init__(self, grid=[torch.ones(1)], r=[1,1]):\n",
    "        super().__init__(n=[grid[k].numel() for k in range(len(grid))], r=r)\n",
    "        self.grid = grid\n",
    "\n",
    "    def interp_core(self, k, x):\n",
    "        return interp1(self.grid[k], x, self.U[k], axis=1)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        prod = self.interp_core(0, X[:,0])\n",
    "        for k in range(1, len(self.U)):\n",
    "            prod = torch.einsum('ijk,kjl->ijl', prod, self.interp_core(k, X[:,k]))\n",
    "        return prod\n",
    "    \n",
    "class TTSqrDE(TTLin): # Squared TT(x) = <U, \\phi(x)>^2 for Density Estimation with log-likelihood loss and normalisation\n",
    "    def __init__(self, grid=[torch.ones(1)], r=[1,1], Lambda=0):\n",
    "        super().__init__(grid,r)\n",
    "        self.Mass = [linearMass(grid[k]) for k in range(len(grid))]\n",
    "        self.Lambda = Lambda\n",
    "        if Lambda > 0:\n",
    "            self.Lap = [[]]*len(grid)\n",
    "            self.Lap[0] = torch.zeros(1, grid[0].numel(), grid[0].numel(), 2)\n",
    "            self.Lap[0][0,:,:,0] = linearLap(grid[0])\n",
    "            self.Lap[0][0,:,:,1] = self.Mass[0]\n",
    "            for k in range(1,len(grid)):\n",
    "                self.Lap[k] = torch.zeros(2, grid[k].numel(), grid[k].numel(), 2)\n",
    "                self.Lap[k][1,:,:,0] = linearLap(grid[k])\n",
    "                self.Lap[k][0,:,:,0] = self.Mass[k]\n",
    "                self.Lap[k][1,:,:,1] = self.Mass[k]\n",
    "            self.Lap[-1] = torch.zeros(2, grid[-1].numel(), grid[-1].numel(), 1)\n",
    "            self.Lap[-1][0,:,:,0] = self.Mass[-1]        \n",
    "            self.Lap[-1][1,:,:,0] = linearLap(grid[-1])\n",
    "        self.marginals = []\n",
    "\n",
    "    def forward(self, X):        \n",
    "        return super().forward(X)**2\n",
    "    \n",
    "    def normconst(self):\n",
    "        self.marginals = [torch.ones(1,1)] * (len(self.U)+1)\n",
    "        for k in range(len(self.U)-1,-1,-1):\n",
    "            V = torch.einsum('ij,kjl->kil', self.Mass[k], self.U[k])\n",
    "            self.marginals[k] = torch.einsum('kil,lp,mip->km', V, self.marginals[k+1], self.U[k])\n",
    "        return self.marginals[0].flatten()\n",
    "    \n",
    "    def lap(self):\n",
    "        if self.Lambda == 0:\n",
    "            return 0\n",
    "        sm = torch.ones(1,1,1)\n",
    "        for k in range(len(self.U)):\n",
    "            V1 = torch.einsum('kqp,pil->kqil', sm, self.U[k])\n",
    "            V2 = torch.einsum('kqil,qijr->kjlr', V1, self.Lap[k])\n",
    "            sm = torch.einsum('kjlr,kjt->lrt', V2, self.U[k])\n",
    "        return sm.flatten() * self.Lambda\n",
    "\n",
    "    def normalise(self):\n",
    "        Z = self.normconst()\n",
    "        if ((Z-1).abs() > 1e-2):\n",
    "            print(f\"Normalising constant {float(Z)} is far from 1\")\n",
    "        Z = Z**(0.5/len(self.U))\n",
    "        for k in range(len(self.U)):\n",
    "            self.U[k].data /= Z\n",
    "    \n",
    "    def loss(self, X):  # Log-likelihood Loss\n",
    "        return torch.mean(torch.log(self.normconst()) - torch.log(self.forward(X))) + self.lap()  # From TERM\n",
    "        # return -torch.mean(torch.log(self.forward(X)))  # From TERM assuming normalisation\n",
    "    \n",
    "    def rt(self, x):\n",
    "        \"\"\"\n",
    "        Forward Rosenblatt transform\n",
    "        \"\"\"\n",
    "        self.normconst() # Compute marginals\n",
    "        prevcond = torch.ones(len(x),1) # Conditioned left cores\n",
    "        q = torch.ones_like(x)\n",
    "        for k in range(len(self.U)):     \n",
    "            Pprev = torch.einsum('mk,kil->mil', prevcond, self.U[k])\n",
    "            dP = Pprev[:,1:,:] - Pprev[:,:-1,:]\n",
    "            Pprev = Pprev[:,:-1,:]\n",
    "            P0 = torch.einsum('mik,mip,kp->mi', Pprev, Pprev, self.marginals[k+1])\n",
    "            P1 = torch.einsum('mik,mip,kp->mi', dP, Pprev, self.marginals[k+1]) * 2\n",
    "            P2 = torch.einsum('mik,mip,kp->mi', dP, dP, self.marginals[k+1])\n",
    "            h = (self.grid[k][1:] - self.grid[k][:-1]).reshape(1,-1)\n",
    "            C0h = (P2/3 + P1/2 + P0) * h\n",
    "            C0h = torch.hstack([torch.zeros(C0h.shape[0], 1), C0h])\n",
    "            C0h = torch.cumsum(C0h, dim=1)  # CDF on grid\n",
    "            Zc  = C0h[:,-1].reshape(-1,1)\n",
    "            izero = (Zc<1e-30).flatten()\n",
    "            C0h[izero,:] = torch.linspace(0, 1, C0h.shape[1])\n",
    "            Zc[izero,:] = 1\n",
    "            P2[izero,:] = 0\n",
    "            P1[izero,:] = 0\n",
    "            P0[izero,:] = 1\n",
    "            C0h = C0h / Zc  # Normalise CDF\n",
    "            ind = torch.searchsorted(self.grid[k], x[:,k]) - 1 # indices on the left of x\n",
    "            ind = torch.minimum(torch.maximum(ind, torch.tensor(0)), torch.tensor(self.grid[k].numel()-2))\n",
    "            ind = ind.reshape(-1,1)\n",
    "            # C0(z) = (p2*z**3/3 + p1*z**2/2 + p0*z) * h + C0\n",
    "            P0 = torch.gather(P0, dim=1, index=ind) / Zc\n",
    "            P1 = torch.gather(P1, dim=1, index=ind) / Zc\n",
    "            P2 = torch.gather(P2, dim=1, index=ind) / Zc\n",
    "            C0h = torch.gather(C0h, dim=1, index=ind)\n",
    "            xl = self.grid[k][ind].reshape(-1,1)\n",
    "            h = self.grid[k][ind+1].reshape(-1,1) - xl            \n",
    "            z = (x[:,k].reshape(-1,1) - xl) / h\n",
    "            q[:,k] = (C0h + (P2 * z**3/3 + P1 * z**2/2 + P0 * z) * h).flatten()\n",
    "            q[:,k] = torch.maximum(torch.minimum(q[:,k], torch.ones_like(q[:,k])), torch.zeros_like(q[:,k]))\n",
    "            prevcond = torch.einsum('mk,kml->ml', prevcond, self.interp_core(k, x[:,k]))\n",
    "            # # Map back to normal\n",
    "            # q[:,k] = torch.erfinv(2*q[:,k]-1)*torch.sqrt(torch.tensor(2))\n",
    "        return q\n",
    "\n",
    "\n",
    "    def irt(self, q):\n",
    "        \"\"\"\n",
    "        Inverse Rosenblatt transform\n",
    "        \"\"\"\n",
    "        # q = torch.erf(qn/torch.sqrt(torch.tensor(2)))/2+0.5\n",
    "        self.normconst() # Compute marginals\n",
    "        prevcond = torch.ones(len(q),1) # Conditioned left cores\n",
    "        lFapp = torch.zeros_like(prevcond)\n",
    "        x = torch.ones_like(q)        \n",
    "        for k in range(len(self.U)):            \n",
    "            Pprev = torch.einsum('mk,kil->mil', prevcond, self.U[k])\n",
    "            dP = Pprev[:,1:,:] - Pprev[:,:-1,:]\n",
    "            Pprev = Pprev[:,:-1,:]\n",
    "            P0 = torch.einsum('mik,mip,kp->mi', Pprev, Pprev, self.marginals[k+1])\n",
    "            P1 = torch.einsum('mik,mip,kp->mi', dP, Pprev, self.marginals[k+1]) * 2\n",
    "            P2 = torch.einsum('mik,mip,kp->mi', dP, dP, self.marginals[k+1])\n",
    "            h = (self.grid[k][1:] - self.grid[k][:-1]).reshape(1,-1)\n",
    "            # h = xr - xl, dp = pr - pl\n",
    "            # z = (x-xl)/h\n",
    "            # p(z) = (pr_k*z + pl_k*(1-z))*P_{kl}*(pr_l*z + pl_l*(1-z))\n",
    "            #      = (prPpr)*z**2 + (prPpl+plPpr)*z*(1-z) + plPpl*(1-z)**2\n",
    "            #      = (prPpr+plPpl-prPpl-plPpr)*z**2 + (prPpl+plPpr-2*plPpl)*z + plPpl\n",
    "            # p0 = plPpl, p1 = prPpl+plPpr-2*p0 = (pr-pl)Ppl + plP(pr-pl), p2 = prPpr-p1-p0 = (pr-pl)P(pr-pl)\n",
    "            # C0(z) = int_0^z p(s)ds = p2*z**3/3 + p1*z**2/2 + p0*z               * h\n",
    "            # C0(h) = (p2/3 + p1/2 + p0) * h                        \n",
    "            C0h = (P2/3 + P1/2 + P0) * h\n",
    "            C0h = torch.hstack([torch.zeros(C0h.shape[0], 1), C0h])\n",
    "            C0h = torch.cumsum(C0h, dim=1)  # CDF on grid\n",
    "            Zc  = C0h[:,-1].reshape(-1,1)\n",
    "            izero = (Zc<1e-30).flatten()\n",
    "            C0h[izero,:] = torch.linspace(0, 1, C0h.shape[1])\n",
    "            Zc[izero,:] = 1\n",
    "            P2[izero,:] = 0\n",
    "            P1[izero,:] = 0\n",
    "            P0[izero,:] = 1\n",
    "            C0h = C0h / Zc  # Normalise CDF\n",
    "            ind = torch.searchsorted(C0h, q[:,k].reshape(-1,1)) - 1 # indices on the left of q\n",
    "            ind = torch.minimum(torch.maximum(ind, torch.tensor(0)), torch.tensor(self.grid[k].numel()-2))\n",
    "            P0 = torch.gather(P0, dim=1, index=ind) / Zc\n",
    "            P1 = torch.gather(P1, dim=1, index=ind) / Zc\n",
    "            P2 = torch.gather(P2, dim=1, index=ind) / Zc\n",
    "            iconst = (P2 < 1e-30).flatten() # Indices where density is constant\n",
    "            ivar   = ~iconst\n",
    "            q0 = q[:,k].reshape(-1,1) - torch.gather(C0h, dim=1, index=ind)\n",
    "            xl = self.grid[k][ind].reshape(-1,1)\n",
    "            h = self.grid[k][ind+1].reshape(-1,1) - xl    \n",
    "            # Sample constant densities -> linear CDF\n",
    "            z = q0[iconst]/P0[iconst]\n",
    "            xk = xl[iconst] + torch.min(torch.max(z, torch.zeros_like(z)), h[iconst])\n",
    "            x[iconst,k] = xk.flatten()\n",
    "            # Solve the cubic equations for the variable densities\n",
    "            P0v = P0[ivar]\n",
    "            P1v = P1[ivar]\n",
    "            P2v = P2[ivar]\n",
    "            D0 = P1v**2/4 - P0v*P2v\n",
    "            D1 = P1v**3/4 - P0v*P1v*P2v*3/2 - 3*P2v**2*q0[ivar]/h[ivar]\n",
    "            DD = D1**2 - 4*D0**3\n",
    "            C = (D1 + D1.sign() * torch.sqrt(DD.abs()))/2\n",
    "            C = C.sign() * C.abs().pow(1.0/3) #   np.cbrt(C.detach().numpy())\n",
    "            z = -(P1v/2 + C + D0/C)/P2v\n",
    "            izero = (C.abs()<1e-30).flatten()\n",
    "            z[izero] = -(P1v[izero]/2)/P2v[izero]\n",
    "            # res = P2/3 * z**3 + P1/2 * z**2 + P0 * z - q0[ivar]/h[ivar]\n",
    "            # print(res)\n",
    "            z = torch.min(torch.max(z, torch.zeros_like(z)), torch.ones_like(z))\n",
    "            xk = xl[ivar] + z*h[ivar]\n",
    "            x[ivar,k] = xk.flatten()\n",
    "            # Condition the current core\n",
    "            prevcond = torch.einsum('mk,kml->ml', prevcond, self.interp_core(k, x[:,k]))\n",
    "            z = (x[:,k].reshape(-1,1) - xl)/h\n",
    "            lFapp += torch.log(P2 * z**2 + P1 * z + P0)\n",
    "        return x, lFapp\n",
    "    \n",
    "    def cross(self, fun, tol=1e-6, nswp=20, kickrank=4, dir=1):\n",
    "        \"\"\"\n",
    "        Amen-cross approximation\n",
    "        fun should take samples of shape (M, d) and return a tensor of shape (M, m)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Aux functions\n",
    "        def maxvol2(A, niters=100, eps=1e-2):\n",
    "            \"\"\"\n",
    "            Maxvol algorithm for selecting the most important rows of a matrix\n",
    "            \"\"\"\n",
    "            P,L,U = torch.linalg.lu(A)\n",
    "            ind = torch.argmax(P, dim=0)[:A.shape[1]]\n",
    "            B = torch.linalg.solve(A[ind,:], A, left=False)\n",
    "            for _ in range(niters):\n",
    "                big_ind = torch.argmax(torch.abs(B))\n",
    "                i0, j0 = torch.unravel_index(big_ind, A.shape)\n",
    "                if torch.abs(B[i0, j0]) <= 1 + eps:\n",
    "                    break\n",
    "                k = ind[j0]\n",
    "                B += B[:, j0].reshape(-1,1) @ ((B[k, :] - B[i0, :]) / B[i0, j0]).reshape(1,-1)\n",
    "                ind[j0] = i0\n",
    "            return ind\n",
    "\n",
    "        def qrmaxvol_block(yl, yr, dir, z=None):\n",
    "            \"\"\"\n",
    "            Move non-orth center between the blocks, computing enrich, QR and maxvol\n",
    "            \"\"\"\n",
    "            r0, nl, _, bl = yl.shape\n",
    "            _, nr, r2, br = yr.shape\n",
    "\n",
    "            if dir > 0:\n",
    "                # Reshape all\n",
    "                yl = yl.reshape(r0 * nl, -1)\n",
    "                r1 = yl.shape[1]\n",
    "                if z is not None:\n",
    "                    # Enrich\n",
    "                    yl = torch.hstack([yl, z])\n",
    "\n",
    "                # QR\n",
    "                yl, rv = torch.linalg.qr(yl)\n",
    "                rv = rv[:, :r1]\n",
    "\n",
    "                # Maxvol and divide\n",
    "                ind = maxvol2(yl)\n",
    "                YY = yl[ind, :]\n",
    "                yl = torch.linalg.solve(YY, yl, left=False)\n",
    "\n",
    "                # Update r\n",
    "                r1 = yl.shape[1]\n",
    "                yl = yl.reshape(r0, nl, r1, bl)\n",
    "\n",
    "                # Cast non-orths\n",
    "                rv = YY @ rv\n",
    "                yr = yr.reshape(-1, nr * r2 * br)\n",
    "                yr = rv @ yr\n",
    "                yr = yr.reshape(r1, nr, r2, br)\n",
    "            else:\n",
    "                # Reshape all\n",
    "                yr = yr.reshape(-1, nr * r2)\n",
    "                r1 = yr.shape[0]\n",
    "                if z is not None:\n",
    "                    # Enrich\n",
    "                    yr = torch.vstack([yr, z])\n",
    "\n",
    "                # QR\n",
    "                yr = yr.T\n",
    "                yr, rv = torch.linalg.qr(yr)\n",
    "                rv = rv[:, :r1]\n",
    "\n",
    "                # Maxvol and divide\n",
    "                # Replace maxvol2 function with its Python equivalent\n",
    "                ind = maxvol2(yr)  # maxvol2 function needs to be defined separately\n",
    "                yr = yr.T\n",
    "                YY = yr[:, ind]\n",
    "                yr = torch.linalg.solve(YY, yr, left=True)\n",
    "\n",
    "                # Update r\n",
    "                r1 = yr.shape[0]\n",
    "                yr = yr.reshape(r1, nr, r2, br)\n",
    "\n",
    "                # Cast non-orths\n",
    "                rv = rv.T @ YY\n",
    "                yl = yl.reshape(-1, bl)\n",
    "                yl = yl.T\n",
    "                yl = yl.reshape(bl * r0 * nl, -1)\n",
    "                yl = yl @ rv\n",
    "                yl = yl.reshape(bl, r0 * nl * r1)\n",
    "                yl = yl.T\n",
    "                yl = yl.reshape(r0, nl, r1, bl)\n",
    "\n",
    "            return yl, yr, ind\n",
    "\n",
    "        def indexmerge(X1, X2, X3=None):\n",
    "            \"\"\"\n",
    "            Merge indices with direct sum\n",
    "            \"\"\"\n",
    "            Y = X2.reshape(1, X2.shape[0], 1, X2.shape[1])\n",
    "            if X1 is not None:\n",
    "                X1 = X1.reshape(X1.shape[0], 1, 1, X1.shape[1])\n",
    "                X1 = torch.tile(X1, [1, Y.shape[1], 1, 1])\n",
    "                Y = torch.tile(Y, [X1.shape[0], 1, 1, 1])\n",
    "                Y = torch.cat([X1, Y], dim=3)\n",
    "            if X3 is not None:\n",
    "                X3 = X3.reshape(1, 1, X3.shape[0], X3.shape[1])\n",
    "                X3 = torch.tile(X3, [Y.shape[0], Y.shape[1], 1, 1])\n",
    "                Y = torch.tile(Y, [1, 1, X3.shape[2], 1])\n",
    "                Y = torch.cat([Y, X3], dim=3)\n",
    "            return Y.reshape(-1, Y.shape[-1])\n",
    "        \n",
    "        def ind2samples(grid, ind):\n",
    "            \"\"\"\n",
    "            Convert indices to samples\n",
    "            \"\"\"\n",
    "            return torch.hstack([grid[i][indi].reshape(-1,1) for i, indi in enumerate(ind.T)])\n",
    "\n",
    "        def start_stop_pos(d, dir, swp):\n",
    "            \"\"\"\n",
    "            Start, end, prev and next dimensions for the cross\n",
    "            \"\"\"\n",
    "            if dir > 0:\n",
    "                return 0, d-1, 0, 1\n",
    "            else:\n",
    "                return d-1, 0, 1, 0\n",
    "\n",
    "        # The cross itself starts here\n",
    "        d = len(self.U)\n",
    "        n = [g.numel() for g in self.grid]\n",
    "        # Initial indices\n",
    "        if (dir>0):\n",
    "            J = [None]+[torch.randint(low=0, high=self.U[i].shape[1], size=(self.U[i].shape[0],len(self.U)-i)) for i in range(1,len(self.U))]+[None]\n",
    "        # Initial QR - goes in the reverse of dir\n",
    "        istart, iend, iprev, inext = start_stop_pos(d, -dir, 0) # Where we start and move next\n",
    "        for i in range(istart, iend, -dir):\n",
    "            self.U[i+inext] = self.U[i+inext].reshape(self.U[i+inext].shape[0], n[i+inext], self.U[i+inext].shape[2], 1)\n",
    "            self.U[i-iprev] = self.U[i-iprev].reshape(self.U[i-iprev].shape[0], n[i-iprev], self.U[i-iprev].shape[2], 1)\n",
    "            self.U[i-iprev], self.U[i+inext], ind = qrmaxvol_block(self.U[i-iprev], self.U[i+inext], -dir)\n",
    "\n",
    "        evalcnt = 0\n",
    "        for swp in range(nswp):\n",
    "            istart, iend, iprev, inext = start_stop_pos(d, dir, swp) # Where we start and move next\n",
    "            max_err = 0            \n",
    "            for i in range(istart, iend, dir):\n",
    "                # Sample\n",
    "                X = ind2samples(self.grid, indexmerge(J[i], torch.arange(n[i]).reshape(-1,1), J[i+1]))\n",
    "                Y = fun(X)\n",
    "                evalcnt += X.shape[0]\n",
    "                Y = Y.reshape(self.U[i].shape)\n",
    "                err = torch.norm(Y - self.U[i]) / torch.norm(Y)\n",
    "                print(f\"\\t swp = {swp}.{i}: err = {err:.3e}\")\n",
    "                max_err = max(max_err, err)\n",
    "                self.U[i] = Y\n",
    "                # Move non-orth center\n",
    "                self.U[i-iprev], self.U[i+inext], ind = qrmaxvol_block(self.U[i-iprev], self.U[i+inext], dir)\n",
    "                # Restrict new indices\n",
    "                if dir > 0:\n",
    "                    J[i+inext] = indexmerge(J[i], torch.arange(n[i]).reshape(-1,1), None)\n",
    "                else:\n",
    "                    J[i+inext] = indexmerge(None, torch.arange(n[i]).reshape(-1,1), J[i+1])\n",
    "                J[i+inext] = J[i+inext][ind, :]\n",
    "\n",
    "            print(f\"Cross sweep {swp}: max_err = {max_err:.3e}, cum#evals = {evalcnt}\")\n",
    "            if max_err < tol:\n",
    "                break\n",
    "            dir = -dir\n",
    "\n",
    "        for i in range(d):\n",
    "            self.U[i] = self.U[i].reshape(self.U[i].shape[0], n[i], self.U[i].shape[2])\n",
    "        return evalcnt    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t swp = 0.0: err = 1.000e+00\n",
      "\t swp = 0.1: err = 3.334e-01\n",
      "Cross sweep 0: max_err = 1.000e+00, cum#evals = 420\n",
      "\t swp = 1.2: err = 4.447e-01\n",
      "\t swp = 1.1: err = 1.324e-03\n",
      "Cross sweep 1: max_err = 4.447e-01, cum#evals = 820\n",
      "\t swp = 2.0: err = 5.646e-05\n",
      "\t swp = 2.1: err = 2.183e-07\n",
      "Cross sweep 2: max_err = 5.646e-05, cum#evals = 1240\n",
      "\t swp = 3.2: err = 8.146e-07\n",
      "\t swp = 3.1: err = 3.833e-07\n",
      "Cross sweep 3: max_err = 8.146e-07, cum#evals = 1640\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(6.0472e-06, grad_fn=<LinalgVectorNormBackward0>)"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = TTSqrDE([torch.linspace(0,9,10)]*3, [1,7,5,1])\n",
    "t.cross(lambda x: 1/torch.sqrt(torch.sum(x+1, dim=1, keepdim=True)), nswp=5)\n",
    "\n",
    "X1, X2, X3 = torch.meshgrid(torch.linspace(0,9,10), torch.linspace(0,9,10), torch.linspace(0,9,10))\n",
    "torch.norm( (t.forward(torch.hstack([X1.reshape(-1,1), X2.reshape(-1,1), X3.reshape(-1,1)]))**(1/2)).reshape(X1.shape) - 1/torch.sqrt(X1+X2+X3+3) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
